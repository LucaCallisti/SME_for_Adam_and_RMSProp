
==================== tau = 0.1, C1 = 1, C2 = 0.5, BETA = (0.9, 0.95), SIGMA = 0.2 ====================

Number of steps: 1000
[DISCRETE] Starting discrete simulations...
[DISCRETE] Simulation 1/4...
Traceback (most recent call last):
  File "/scratch/callisti/Thesis-enc/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/scratch/callisti/Thesis-enc/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/home/callisti/Thesis/Code_2025-11-22/NeuralNetwork/main_v3.py", line 569, in <module>
    main()
  File "/data/home/callisti/Thesis/Code_2025-11-22/NeuralNetwork/main_v3.py", line 560, in main
    run_experiment_configuration(
  File "/data/home/callisti/Thesis/Code_2025-11-22/NeuralNetwork/main_v3.py", line 439, in run_experiment_configuration
    res_disc = run_discrete_simulations(
  File "/data/home/callisti/Thesis/Code_2025-11-22/NeuralNetwork/main_v3.py", line 217, in run_discrete_simulations
    res, loss_values_disc = regime_funcs['discr_fun'](
  File "/data/home/callisti/Thesis/Code_2025-11-22/Algorithms/Balistic_regime_Adam.py", line 226, in Discrete_Adam_balistic_regime
    grad = funz.grad(x, gamma)
  File "/data/home/callisti/Thesis/Code_2025-11-22/NeuralNetwork/Dnn.py", line 113, in grad
    return self.autograd_vector_batch(theta - gamma)
  File "/data/home/callisti/Thesis/Code_2025-11-22/NeuralNetwork/Dnn.py", line 131, in autograd_vector_batch
    self.grad_batch = batched_grad(theta_batch)
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/apis.py", line 201, in wrapped
    return vmap_impl(
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/vmap.py", line 331, in vmap_impl
    return _flat_vmap(
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/vmap.py", line 48, in fn
    return f(*args, **kwargs)
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/vmap.py", line 480, in _flat_vmap
    batched_outputs = func(*batched_inputs, **kwargs)
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/apis.py", line 397, in wrapper
    return eager_transforms.grad_impl(func, argnums, has_aux, args, kwargs)
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/eager_transforms.py", line 1451, in grad_impl
    results = grad_and_value_impl(func, argnums, has_aux, args, kwargs)
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/vmap.py", line 48, in fn
    return f(*args, **kwargs)
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/eager_transforms.py", line 1435, in grad_and_value_impl
    flat_grad_input = _autograd_grad(
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/_functorch/eager_transforms.py", line 181, in _autograd_grad
    grad_inputs = torch.autograd.grad(
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/autograd/__init__.py", line 436, in grad
    result = _engine_run_backward(
  File "/scratch/callisti/Thesis-enc/lib/python3.8/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
